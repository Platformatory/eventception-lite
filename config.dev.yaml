# service:
name: api-log-processor
description: Service to process request-response (or network flow) logs from Kafka topic.

kafka:
  config:
    # bootstrapServers: "pkc-p11xm.us-east-1.aws.confluent.cloud:9092" # e.g., "streams-cluster-bootstrap-server:9092"
    bootstrapServers: localhost:9092
    streamsProperties:
      application.id: "your-application-id"
      default.key.serde: "org.apache.kafka.common.serialization.Serdes$StringSerde"
      default.value.serde: "org.apache.kafka.common.serialization.Serdes$StringSerde"
      state.dir: "/tmp/kafka-streams"
      consumer:
        max.poll.records: 500
        session.timeout.ms: 10000
      producer:
        acks: "all"
        retries: 3
        batch.size: 16384
        linger.ms: 1
      adminClient:
        retries: 5
        request.timeout.ms: 30000
    connectProperties:
      group.id: "eventception-connect"
      key.converter: org.apache.kafka.connect.storage.StringConverter
      value.converter: org.apache.kafka.connect.json.JsonConverter
    authentication:
      # sasl.mechanism: "PLAIN"
      # security.protocol: "SASL_SSL"
      security.protocol: "PLAINTEXT"
      # security.protocol: "SASL_PLAINTEXT"
      # sasl.jaas.config: "org.apache.kafka.common.security.plain.PlainLoginModule required username='admin' password='admin-secret';"
      # sasl.jaas.config: "org.apache.kafka.common.security.plain.PlainLoginModule required username='4X7U6FFNZA3YVKEY' password='e8EgQMlWvcb/iaL5jUZSE9UDD0sQFcksjC1jBoao+lLWosyCDw78oEjbMA4tv9yJ';"

topologies:
  - name: api-cdc-pipeline
    input:
      topics: "api-logs-.*" # Regex pattern to subscribe to input topics
    processors:
      - type: CelFilter
        name: filter
        celExpression: "request.path == '/orders' && (response.status == 200 || response.status == 201)"
      - type: JSONTransform
        name: transform
        transform:
          key: '$join([$substring(request.path, 1), "-", request.body.order_id])'
          value: '{"specversion": "1.0", "action": request.method="POST" ? "create-order": request.method="PUT" ? "update-order" : "unkown", "source": client.ip, "id": request.body.order_id, "orderplaced": $fromMillis(request.time), "orderprocessed": response.headers.date, "order_quantity": request.body.quantity}'
          # value: '{"specversion": "1.0", "action": request.method="POST" ? "create-order": request.method="PUT" ? "update-order" : "unkown", "source": client.ip, "id": request.body.order_id, "orderplaced": $fromMillis(request.time, "[FNn,3], [D01] [MNn,3] [Y0001] [h01]:[m01]:[s01] [z]"), "orderprocessed": response.headers.date}'
      - type: ChangeDataCapture
        name: cdc
        keyLookupExpression: "request.id" # Not implemented
    output:
      topic: "orders-cdc" # CEL expression for dynamic output evaluation, CEL expression not implemented
      dlq: "orders-cdc-dlq" # CEL expression for dynamic DLQ evaluation

# connectors:
#   - type: WebhookSink
#     name: mylittleservice
#     config:
#       url: http://kong:8000/demo
#       headers: "Content-Type:application/json" # Comma separated
#       authentication:
#         type: basic # none, basic, bearer
#         username: demouser
#         password: OpenSesame
# TODO: Separate YAML files, k8s style


  # - name: change-data-pipeline
  #   input:
  #     topics: "cdc-logs-.*" # Regex pattern to subscribe to input topics
  #   processors:
  #     - type: change-data
  #       keyLookupExpression: "request.id"
  #   output:
  #     topic: "'${changeDataOutputTopic}'" # CEL expression for dynamic output evaluation
  #     dlq: "'${changeDataDlqTopic}'" # CEL expression for dynamic DLQ evaluation